{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc593f0-a5bd-471b-9a14-a355758071fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# a simple self-attention mechanism calculation for a randomly taken encoded input sequence \n",
    "# values with a single head. The actual Transformer architecture used multi-headed attention\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# a simple encoded sentence\n",
    "sentence = torch.tensor([0, 2, 8, 4, 1, 8, 5, 2])\n",
    "# embed sentence tensor with 10 vocab_size and 16 embed_dim\n",
    "torch.manual_seed(42)\n",
    "embed = torch.nn.Embedding(10, 16)\n",
    "# each element in sentence tensor is converted to 16-dim embedded tensor. So shape is (8X16)\n",
    "embedded_sentence = embed(sentence)\n",
    "\n",
    "# calcualte query, key and value role projection tensors\n",
    "\n",
    "# step1: define query, key, value weights to calculate above q, k, v\n",
    "# shapes of these values are going to be dXd where shape of input sequence is nXd\n",
    "# the input seq has shape 8X16. so the weights have shape 16X16 because these weights are \n",
    "# to be dotted with each input item in the sequence to generate corresponding q, k and v values of each input item\n",
    "d = embedded_sentence.shape[1]\n",
    "torch.manual_seed(42)\n",
    "W_query = torch.rand(d, d)\n",
    "W_key = torch.rand(d, d)\n",
    "W_value = torch.rand(d, d)\n",
    "\n",
    "# calculate query, key and value projection matrices\n",
    "queries = torch.matmul(embedded_sentence, W_query)\n",
    "keys = torch.matmul(embedded_sentence, W_key)\n",
    "values = torch.matmul(embedded_sentence, W_value)\n",
    "\n",
    "# calculate alignment scores by dot product(.matmul() internally is bunch of dot products) \n",
    "# now we have the scores for how each input is related to or similar to other input items in the enitre sequence \n",
    "omega = torch.matmul(queries, keys.T)\n",
    "\n",
    "# normalise the values for prob distribution using softmax\n",
    "attn_weights = F.softmax(omega / d**0.5, dim=1)\n",
    "print(attn_weights.sum(dim=1))\n",
    "\n",
    "#weigted sum over 'values' to calcualte the output of self-attention layer\n",
    "z = torch.matmul(attn_weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70e14e32-1a14-49e5-8abb-9b4104c78590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n",
      "torch.Size([8, 8, 16])\n",
      "torch.Size([8, 8, 8])\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "torch.Size([8, 8, 8])\n",
      "torch.Size([8, 8, 16])\n",
      "torch.Size([8, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# The actual Transformer architecture uses multi-headed self-attention mechanism\n",
    "# which isi multiple sets of query, key and values. Each input item in the sequence gets\n",
    "# its own query, key and value role projection matrices\n",
    "\n",
    "import torch\n",
    "\n",
    "sentence = torch.tensor([2, 1, 9, 3, 7, 0, 3, 6])\n",
    "embed = torch.nn.Embedding(10, 16)\n",
    "embedded_sentence = embed(sentence)\n",
    "\n",
    "print(embedded_sentence.shape)\n",
    "\n",
    "# define multiple sets of weights to calculate Q, K and V\n",
    "h = 8 # number of sets of each weights\n",
    "d = embedded_sentence.shape[1]\n",
    "multihead_W_query = torch.rand(h, d, d)\n",
    "multihead_W_key = torch.rand(h, d, d)\n",
    "multihead_W_value = torch.rand(h, d, d)\n",
    "\n",
    "# adjusting embedded input shape to be comaptible with weight tensors\n",
    "stacked_inputs = embedded_sentence.T.repeat(h, 1, 1)\n",
    "\n",
    "#calculate multihead q, k and v\n",
    "mulithead_queries = torch.bmm(multihead_W_query, stacked_inputs)\n",
    "mulithead_queries = mulithead_queries.permute(0, 2, 1)\n",
    "print(mulithead_queries.shape)\n",
    "multihead_keys = torch.bmm(multihead_W_key, stacked_inputs)\n",
    "multihead_keys = multihead_keys.permute(0, 2, 1)\n",
    "multihead_values = torch.bmm(multihead_W_value, stacked_inputs)\n",
    "multihead_values = multihead_values.permute(0, 2, 1)\n",
    "\n",
    "# comparison step or the dotting to calculate similarity scores\n",
    "omega = torch.bmm(mulithead_queries, multihead_keys.permute(0, 2, 1))\n",
    "print(omega.shape)\n",
    "\n",
    "# calculate attention weights for all the inputs using softmax\n",
    "attn_weights = torch.nn.functional.softmax(omega / d**0.5, dim=1)\n",
    "print(attn_weights.sum(dim=1))\n",
    "\n",
    "#calculate self-attention layer output(contexts) using weighted sum over 'multihead values'\n",
    "print(attn_weights.shape)\n",
    "print(multihead_values.shape)\n",
    "z = torch.bmm(attn_weights, multihead_values)\n",
    "print(z.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
